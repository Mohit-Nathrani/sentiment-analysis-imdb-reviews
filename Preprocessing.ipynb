{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking into the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/aclImdb/\"\n",
    "positiveFiles = [x for x in os.listdir(path+\"train/pos/\") if x.endswith(\".txt\")]\n",
    "negativeFiles = [x for x in os.listdir(path+\"train/neg/\") if x.endswith(\".txt\")]\n",
    "testPositiveFiles = [x for x in os.listdir(path+\"test/pos\") if x.endswith(\".txt\")]\n",
    "testNegativeFiles = [x for x in os.listdir(path+\"test/neg\") if x.endswith(\".txt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500 12500\n"
     ]
    }
   ],
   "source": [
    "print(len(positiveFiles),len(negativeFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500 12500\n"
     ]
    }
   ],
   "source": [
    "print(len(testPositiveFiles),len(testNegativeFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Having watched this film strictly on the strength of reviewers' ratings I was most pleasantly surprised. Although clearly low-budget, it bears the signs of clever ingenuity. For example, when Julia wakes in the strange house and looks out the window I found myself thinking that her sense of isolation would be enhanced with an exterior shot focused on her face and then moving backwards to include the house and its isolated location. And lo and behold! the next scene was exactly that last shot of the house standing lonely on the cliff at the water's edge. There are other examples of how a clever director can elevate his film to the level of a very enjoyable thriller. Savvy viewers will surely spot them but should rest assured they will not be disappointed.<br /><br />As to the performances, George Macready is his usual creepy self, barely maintaining his composure while suggesting a capacity for unadulterated violence. Nina Foch was surprisingly good as the no-nonsense working girl who's not about to submit without a fight. But Dame May Witty, oh boy, she even had me doubting my own eyes and believing she could get away with her evil schemes.<br /><br />This a real diamond in the rough and not to be missed.\n"
     ]
    }
   ],
   "source": [
    "with open(path+\"train/pos/\"+positiveFiles[4], encoding=\"latin1\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Definitely one of the lesser of the Astaire/Rogers musicals. It's just very poorly plotted and paced. It only runs a few minutes longer than Swing Time, for example, but it feels a heck of a lot longer. This is partly due to the secondary romance between Randolph Scott and Harriet Hilliard. Scott is rarely ever interesting. I like Hilliard. She's sweet, and I love at least one of her songs, \"But Where Are You?\" (\"Get Thee Behind Me Satan\", her other number, is a weak leftover from Top Hat, thankfully cut from that masterpiece). Follow the Fleet would actually be a bad film if not for at least three brilliant dance sequences between Astaire and Rogers. The dancing contest vies for the top spot of any of their numbers. The dance is just fantastic. \"I'm Putting All My Eggs in One Basket\" presents the two rehearsing a dance that they don't quite have perfected yet. Its imperfections make it all the more perfect. And \"Let's Face the Music and Dance\" is easily one of Irving Berlin's best songs. So the film is well worth watching for its great moments.\n"
     ]
    }
   ],
   "source": [
    "with open(path+\"train/pos/\"+positiveFiles[2000], encoding=\"latin1\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data and Cleaning\n",
    "* Remove punctuation from words (e.g. ‘what’s’).\n",
    "* Removing tokens that are just punctuation (e.g. ‘-‘).\n",
    "* Removing tokens that contain numbers (e.g. ’10/10′).\n",
    "* Remove tokens that have one character (e.g. ‘a’).\n",
    "* Remove tokens that don’t have much meaning (e.g. ‘and’)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "def clean_doc(text):\n",
    "    # split into tokens\n",
    "    tokens = text.lower().split()\n",
    "    # remove punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    # remove tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    # filtering out short tokens\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y, test_X, test_y = [], [], [], []\n",
    "\n",
    "for pfile in positiveFiles:\n",
    "    with open(path+\"train/pos/\"+pfile, encoding=\"latin1\") as f:\n",
    "        text = clean_doc(f.read())\n",
    "        train_X.append(text)\n",
    "        train_y.append(1)\n",
    "for nfile in negativeFiles:\n",
    "    with open(path+\"train/neg/\"+nfile, encoding=\"latin1\") as f:\n",
    "        text = clean_doc(f.read())\n",
    "        train_X.append(text)\n",
    "        train_y.append(0)\n",
    "        \n",
    "for tpfile in testPositiveFiles:\n",
    "    with open(path+\"test/pos/\"+tpfile, encoding=\"latin1\") as f:\n",
    "        text = clean_doc(f.read())\n",
    "        test_X.append(text)\n",
    "        test_y.append(1)\n",
    "for tnfile in testNegativeFiles:\n",
    "    with open(path+\"test/neg/\"+tnfile, encoding=\"latin1\") as f:\n",
    "        text = clean_doc(f.read())\n",
    "        test_X.append(text)\n",
    "        test_y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'watched film strictly strength reviewers ratings pleasantly surprised although clearly lowbudget bears signs clever ingenuity example julia wakes strange house looks window found thinking sense isolation would enhanced exterior shot focused face moving backwards include house isolated location lo behold next scene exactly last shot house standing lonely cliff waters edge examples clever director elevate film level enjoyable thriller savvy viewers surely spot rest assured disappointedbr br performances george macready usual creepy self barely maintaining composure suggesting capacity unadulterated violence nina foch surprisingly good nononsense working girl whos submit without fight dame may witty oh boy even doubting eyes believing could get away evil schemesbr br real diamond rough missed'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaned data\n",
    "train_X[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'woman aunt go scotland locate evasive muchmaligned film denouement point interesting wellacted eerie fine set design william cameron menzies developed projection veronica hurst captivating genteel sort chic british marilyn monroe still love richard carlson hiding family secret forbidding castle even bats belfry moves leisurely final extraordinary setpiece hurst aunt katherine emery also narrator sneak castle night venture maze find theyre looking center kid always remembered sequence theres nothing scarier claustrophobic finding way high maze hedges naturally two women get separated setting stage engrossing suspense horrific music final result mildly disappointing really since carlsons epilogue end makes sense goingson even provoking sympathy worth seeing'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling data\n",
    "from sklearn.utils import shuffle\n",
    "train_X, train_y = shuffle(train_X, train_y, random_state=0)\n",
    "test_X, test_y = shuffle(test_X, test_y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reason dont give movie fewer stars isnt quite par movie like manos hands fate movies greatest crime fact headmeltingly boring terribly unforgivably british premise movie sounds potentially promising whole teleporting concept direction went completely uninteresting movie research funding bowties projecting lasers actors wooden unemotional aloof love affair two scientists anything intriguing never able tell attraction chemistry nonexistent really understand meltyfaced main guy decided slaughter everyone met least know always give someone fair hearing cut research grants else go rampaging killing wantonly goofy hand gestures 0\n"
     ]
    }
   ],
   "source": [
    "print(train_X[2],train_y[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "word2vec = {}\n",
    "with open('./data/glove/glove.6B.100d.txt') as f:\n",
    "  for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vec = np.asarray(values[1:], dtype='float32')\n",
    "    word2vec[word] = vec\n",
    "print('Found %s word vectors.' % len(word2vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization and padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count=0\n",
    "for i,text in enumerate(train_X):\n",
    "    if len(text.split())>500:\n",
    "        count+=1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 500\n",
    "MAX_VOCAB_SIZE = 30000\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(train_X)\n",
    "train_X = tokenizer.texts_to_sequences(train_X)\n",
    "test_X = tokenizer.texts_to_sequences(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 117014 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "word2idx = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train_X and test_X: (25000, 500) (25000, 500)\n"
     ]
    }
   ],
   "source": [
    "train_X = pad_sequences(train_X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "test_X = pad_sequences(test_X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of train_X and test_X:', train_X.shape, test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data_pickle/train_X.pkl\",\"wb\") as f:\n",
    "    pickle.dump(train_X,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data_pickle/train_y.pkl\",\"wb\") as f:\n",
    "    pickle.dump(train_y,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data_pickle/test_X.pkl\",\"wb\") as f:\n",
    "    pickle.dump(test_X,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data_pickle/test_y.pkl\",\"wb\") as f:\n",
    "    pickle.dump(test_y,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare_embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117014/117014 [00:00<00:00, 681853.88it/s]\n"
     ]
    }
   ],
   "source": [
    "num_words = min(MAX_VOCAB_SIZE, len(word2idx) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in tqdm(word2idx.items(),total=len(word2idx)):\n",
    "  if i < MAX_VOCAB_SIZE:\n",
    "    embedding_vector = word2vec.get(word)\n",
    "    if embedding_vector is not None:\n",
    "      # words not found in embedding index will be all zeros.\n",
    "      embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data_pickle/embedding_matrix.pkl\",\"wb\") as f:\n",
    "    pickle.dump(embedding_matrix,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
